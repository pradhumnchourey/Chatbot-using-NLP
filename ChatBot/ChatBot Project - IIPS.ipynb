{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answer Chatbot using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under the Guidance of : Dr. Rahul Singhai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitted by : \n",
    "### Poorvi Sharma         [IC-2k19-59]\n",
    "### Pradhumn Chourey [IC-2k19-60] \n",
    "### Samriddhi Jariya     [IC-2k19-76]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 1,\n",
       " 'travelled': 2,\n",
       " 'no': 3,\n",
       " 'back': 4,\n",
       " 'yes': 5,\n",
       " 'football': 6,\n",
       " 'office': 7,\n",
       " 'in': 8,\n",
       " 'went': 9,\n",
       " 'discarded': 10,\n",
       " 'moved': 11,\n",
       " 'dropped': 12,\n",
       " 'left': 13,\n",
       " '?': 14,\n",
       " 'the': 15,\n",
       " 'john': 16,\n",
       " 'to': 17,\n",
       " 'sandra': 18,\n",
       " 'grabbed': 19,\n",
       " 'apple': 20,\n",
       " 'got': 21,\n",
       " 'mary': 22,\n",
       " 'took': 23,\n",
       " 'kitchen': 24,\n",
       " 'up': 25,\n",
       " 'picked': 26,\n",
       " 'put': 27,\n",
       " 'milk': 28,\n",
       " '.': 29,\n",
       " 'garden': 30,\n",
       " 'is': 31,\n",
       " 'daniel': 32,\n",
       " 'down': 33,\n",
       " 'hallway': 34,\n",
       " 'bathroom': 35,\n",
       " 'bedroom': 36,\n",
       " 'journeyed': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 15, 36, 29],\n",
       "       [ 0,  0,  0, ..., 15, 30, 29],\n",
       "       [ 0,  0,  0, ..., 15, 30, 29],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 15, 20, 29],\n",
       "       [ 0,  0,  0, ..., 15, 30, 29],\n",
       "       [ 0,  0,  0, ..., 20,  1, 29]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 16,  8, 15, 24, 14],\n",
       "       [31, 16,  8, 15, 24, 14],\n",
       "       [31, 16,  8, 15, 30, 14],\n",
       "       ...,\n",
       "       [31, 22,  8, 15, 36, 14],\n",
       "       [31, 18,  8, 15, 30, 14],\n",
       "       [31, 22,  8, 15, 30, 14]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0., 503.,   0., 497.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, None, 64)     2432        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 6, 64)        2432        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 156, 6)       0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 7s 16ms/step - loss: 0.9794 - accuracy: 0.4842 - val_loss: 0.6953 - val_accuracy: 0.4960\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.7070 - accuracy: 0.4993 - val_loss: 0.6951 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6959 - accuracy: 0.5105 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6954 - accuracy: 0.5014 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6947 - accuracy: 0.5012 - val_loss: 0.6960 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6950 - accuracy: 0.4917 - val_loss: 0.6945 - val_accuracy: 0.5030\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6943 - accuracy: 0.4977 - val_loss: 0.6935 - val_accuracy: 0.4950\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.6946 - accuracy: 0.4952 - val_loss: 0.6948 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.6945 - accuracy: 0.4956 - val_loss: 0.6965 - val_accuracy: 0.4970\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.6941 - accuracy: 0.4964 - val_loss: 0.6943 - val_accuracy: 0.4790\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6906 - val_accuracy: 0.5020\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.6761 - accuracy: 0.5510 - val_loss: 0.6758 - val_accuracy: 0.5470\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.6511 - accuracy: 0.6059 - val_loss: 0.6408 - val_accuracy: 0.6300\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6375 - accuracy: 0.6336 - val_loss: 0.6346 - val_accuracy: 0.6500\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.6269 - accuracy: 0.6525 - val_loss: 0.6230 - val_accuracy: 0.6640\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.6136 - accuracy: 0.6673 - val_loss: 0.6148 - val_accuracy: 0.6650\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6099 - accuracy: 0.6765 - val_loss: 0.6124 - val_accuracy: 0.6700\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.5922 - accuracy: 0.6973 - val_loss: 0.5863 - val_accuracy: 0.6950\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.5827 - accuracy: 0.7102 - val_loss: 0.5656 - val_accuracy: 0.7090\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.5567 - accuracy: 0.7306 - val_loss: 0.5329 - val_accuracy: 0.7380\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.5349 - accuracy: 0.7469 - val_loss: 0.5285 - val_accuracy: 0.7480\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.5103 - accuracy: 0.7606 - val_loss: 0.5153 - val_accuracy: 0.7380\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4978 - accuracy: 0.7636 - val_loss: 0.4828 - val_accuracy: 0.7570\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4935 - accuracy: 0.7697 - val_loss: 0.5055 - val_accuracy: 0.7490\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4854 - accuracy: 0.7684 - val_loss: 0.4992 - val_accuracy: 0.7570\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.4732 - accuracy: 0.7789 - val_loss: 0.4514 - val_accuracy: 0.7700\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.4543 - accuracy: 0.7919 - val_loss: 0.4447 - val_accuracy: 0.7740\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4475 - accuracy: 0.7916 - val_loss: 0.4586 - val_accuracy: 0.7760\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.4361 - accuracy: 0.7970 - val_loss: 0.4442 - val_accuracy: 0.7700\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.4303 - accuracy: 0.7974 - val_loss: 0.4247 - val_accuracy: 0.7780\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.4270 - accuracy: 0.8028 - val_loss: 0.4397 - val_accuracy: 0.7820\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4239 - accuracy: 0.8040 - val_loss: 0.4289 - val_accuracy: 0.7800\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.4185 - accuracy: 0.8048 - val_loss: 0.4409 - val_accuracy: 0.7760\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4129 - accuracy: 0.8052 - val_loss: 0.4186 - val_accuracy: 0.7800\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4105 - accuracy: 0.8109 - val_loss: 0.4134 - val_accuracy: 0.7910\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4035 - accuracy: 0.8165 - val_loss: 0.4127 - val_accuracy: 0.7930\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.4045 - accuracy: 0.8139 - val_loss: 0.4164 - val_accuracy: 0.7900\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3996 - accuracy: 0.8129 - val_loss: 0.4165 - val_accuracy: 0.7880\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3993 - accuracy: 0.8177 - val_loss: 0.4126 - val_accuracy: 0.7920\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.3899 - accuracy: 0.8212 - val_loss: 0.4242 - val_accuracy: 0.7900\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.3912 - accuracy: 0.8184 - val_loss: 0.4076 - val_accuracy: 0.7860\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3905 - accuracy: 0.8182 - val_loss: 0.4329 - val_accuracy: 0.7790\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.3810 - accuracy: 0.8234 - val_loss: 0.4107 - val_accuracy: 0.7940\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.3814 - accuracy: 0.8222 - val_loss: 0.4084 - val_accuracy: 0.7920\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3783 - accuracy: 0.8257 - val_loss: 0.4273 - val_accuracy: 0.7900\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.3744 - accuracy: 0.8298 - val_loss: 0.4041 - val_accuracy: 0.8000\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 10s 30ms/step - loss: 0.3732 - accuracy: 0.8275 - val_loss: 0.4104 - val_accuracy: 0.7910\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3695 - accuracy: 0.8335 - val_loss: 0.4139 - val_accuracy: 0.7880\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.3669 - accuracy: 0.8296 - val_loss: 0.4213 - val_accuracy: 0.7910\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.3611 - accuracy: 0.8357 - val_loss: 0.4329 - val_accuracy: 0.7840\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3563 - accuracy: 0.8400 - val_loss: 0.4466 - val_accuracy: 0.7890\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.3582 - accuracy: 0.8389 - val_loss: 0.4123 - val_accuracy: 0.7910\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3567 - accuracy: 0.8356 - val_loss: 0.4096 - val_accuracy: 0.7970\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3514 - accuracy: 0.8401 - val_loss: 0.4161 - val_accuracy: 0.7900\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.3500 - accuracy: 0.8400 - val_loss: 0.4185 - val_accuracy: 0.7940\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3512 - accuracy: 0.8403 - val_loss: 0.4287 - val_accuracy: 0.7870\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 34ms/step - loss: 0.3457 - accuracy: 0.8461 - val_loss: 0.4056 - val_accuracy: 0.8070\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3418 - accuracy: 0.8468 - val_loss: 0.4314 - val_accuracy: 0.7990\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.3406 - accuracy: 0.8492 - val_loss: 0.4262 - val_accuracy: 0.7910\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.3393 - accuracy: 0.8474 - val_loss: 0.4222 - val_accuracy: 0.8010\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.3386 - accuracy: 0.8487 - val_loss: 0.4265 - val_accuracy: 0.7970\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.3356 - accuracy: 0.8522 - val_loss: 0.4153 - val_accuracy: 0.7940\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3320 - accuracy: 0.8470 - val_loss: 0.4359 - val_accuracy: 0.7950\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.3385 - accuracy: 0.8494 - val_loss: 0.4162 - val_accuracy: 0.8060\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3263 - accuracy: 0.8519 - val_loss: 0.4247 - val_accuracy: 0.8020\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.3272 - accuracy: 0.8543 - val_loss: 0.4382 - val_accuracy: 0.8030\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3266 - accuracy: 0.8518 - val_loss: 0.4262 - val_accuracy: 0.8010\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3234 - accuracy: 0.8585 - val_loss: 0.4340 - val_accuracy: 0.7980\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.3253 - accuracy: 0.8566 - val_loss: 0.4688 - val_accuracy: 0.7920\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.3237 - accuracy: 0.8553 - val_loss: 0.4183 - val_accuracy: 0.8050\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.3198 - accuracy: 0.8568 - val_loss: 0.4577 - val_accuracy: 0.7930\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3196 - accuracy: 0.8588 - val_loss: 0.4284 - val_accuracy: 0.7970\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3132 - accuracy: 0.8644 - val_loss: 0.4405 - val_accuracy: 0.8040\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.3152 - accuracy: 0.8595 - val_loss: 0.4424 - val_accuracy: 0.7960\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3088 - accuracy: 0.8633 - val_loss: 0.4493 - val_accuracy: 0.8000\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.3060 - accuracy: 0.8650 - val_loss: 0.4391 - val_accuracy: 0.8060\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3104 - accuracy: 0.8639 - val_loss: 0.4462 - val_accuracy: 0.7980\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.3043 - accuracy: 0.8658 - val_loss: 0.4500 - val_accuracy: 0.8070\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.3007 - accuracy: 0.8677 - val_loss: 0.4833 - val_accuracy: 0.7980\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3079 - accuracy: 0.8639 - val_loss: 0.4659 - val_accuracy: 0.7950\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.2977 - accuracy: 0.8685 - val_loss: 0.4680 - val_accuracy: 0.8040\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.3018 - accuracy: 0.8646 - val_loss: 0.4678 - val_accuracy: 0.8000\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.2927 - accuracy: 0.8741 - val_loss: 0.4927 - val_accuracy: 0.7950\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2935 - accuracy: 0.8717 - val_loss: 0.4702 - val_accuracy: 0.8050\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2895 - accuracy: 0.8745 - val_loss: 0.4616 - val_accuracy: 0.7980\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2965 - accuracy: 0.8693 - val_loss: 0.4779 - val_accuracy: 0.7990\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.2919 - accuracy: 0.8748 - val_loss: 0.4557 - val_accuracy: 0.8020\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.2883 - accuracy: 0.8749 - val_loss: 0.4912 - val_accuracy: 0.7990\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.2826 - accuracy: 0.8774 - val_loss: 0.4550 - val_accuracy: 0.8130\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.2809 - accuracy: 0.8783 - val_loss: 0.4890 - val_accuracy: 0.8090\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2907 - accuracy: 0.8761 - val_loss: 0.4576 - val_accuracy: 0.8040\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.2838 - accuracy: 0.8781 - val_loss: 0.4648 - val_accuracy: 0.8080\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.2825 - accuracy: 0.8763 - val_loss: 0.4850 - val_accuracy: 0.8050\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2774 - accuracy: 0.8808 - val_loss: 0.5076 - val_accuracy: 0.8080\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.2831 - accuracy: 0.8791 - val_loss: 0.4888 - val_accuracy: 0.8170\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2775 - accuracy: 0.8799 - val_loss: 0.4834 - val_accuracy: 0.8090\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.2742 - accuracy: 0.8836 - val_loss: 0.5066 - val_accuracy: 0.8020\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2743 - accuracy: 0.8833 - val_loss: 0.4925 - val_accuracy: 0.8140\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.2686 - accuracy: 0.8847 - val_loss: 0.5385 - val_accuracy: 0.8010\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2718 - accuracy: 0.8833 - val_loss: 0.5201 - val_accuracy: 0.8110\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2738 - accuracy: 0.8795 - val_loss: 0.5406 - val_accuracy: 0.8080\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2673 - accuracy: 0.8849 - val_loss: 0.5410 - val_accuracy: 0.8030\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.2618 - accuracy: 0.8915 - val_loss: 0.5443 - val_accuracy: 0.8090\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2627 - accuracy: 0.8865 - val_loss: 0.5537 - val_accuracy: 0.8030\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.2605 - accuracy: 0.8882 - val_loss: 0.5156 - val_accuracy: 0.8180\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2700 - accuracy: 0.8839 - val_loss: 0.5452 - val_accuracy: 0.8000\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2631 - accuracy: 0.8877 - val_loss: 0.5277 - val_accuracy: 0.8100\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2624 - accuracy: 0.8884 - val_loss: 0.5241 - val_accuracy: 0.8100\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.2524 - accuracy: 0.8925 - val_loss: 0.5412 - val_accuracy: 0.8150\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2541 - accuracy: 0.8929 - val_loss: 0.5590 - val_accuracy: 0.8120\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2520 - accuracy: 0.8933 - val_loss: 0.5513 - val_accuracy: 0.8120\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2504 - accuracy: 0.8929 - val_loss: 0.5617 - val_accuracy: 0.8170\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2520 - accuracy: 0.8965 - val_loss: 0.5732 - val_accuracy: 0.8020\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2510 - accuracy: 0.8946 - val_loss: 0.5552 - val_accuracy: 0.8080\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.2515 - accuracy: 0.8960 - val_loss: 0.5337 - val_accuracy: 0.8100\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2477 - accuracy: 0.8937 - val_loss: 0.5970 - val_accuracy: 0.8020\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.2468 - accuracy: 0.8947 - val_loss: 0.5377 - val_accuracy: 0.8000\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2472 - accuracy: 0.8948 - val_loss: 0.5474 - val_accuracy: 0.8020\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.2544 - accuracy: 0.8938 - val_loss: 0.5694 - val_accuracy: 0.8030\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2553 - accuracy: 0.8952 - val_loss: 0.5477 - val_accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99998784\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.7901444\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitted By: \n",
    "    Poorvi Sharma    [IC-2k19-59]\n",
    "    Pradhumn Chourey [IC-2k19-60]\n",
    "    Samriddhi Jariya [IC-2k19-59]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
